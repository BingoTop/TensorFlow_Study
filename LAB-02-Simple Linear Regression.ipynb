{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\p1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "W = tf.Variable(2.9) # 임의값\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "# Hypothesis = W * x +b\n",
    "hypothesis = W * x_data + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(), dtype=float32, numpy=45.660004>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data)) # 차원이 줄어들면서 평균을 구한다.\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|    2.4520     0.376| 45.660004\n",
      "   10|    1.1036  0.003398|  0.206336\n",
      "   20|    1.0128  -0.02091|  0.001026\n",
      "   30|    1.0065  -0.02184|  0.000093\n",
      "   40|    1.0059  -0.02123|  0.000083\n",
      "   50|    1.0057  -0.02053|  0.000077\n",
      "   60|    1.0055  -0.01984|  0.000072\n",
      "   70|    1.0053  -0.01918|  0.000067\n",
      "   80|    1.0051  -0.01854|  0.000063\n",
      "   90|    1.0050  -0.01793|  0.000059\n",
      "  100|    1.0048  -0.01733|  0.000055\n"
     ]
    }
   ],
   "source": [
    "#Gradient descent cost를 경사를 하강하면서 미니마이즈하여 W,b를 찾음\n",
    "learning_rate = 0.01\n",
    "for i in range(100+1):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis -  y_data))\n",
    "\n",
    "        W_grad,b_grad = tape.gradient(cost,[W,b]) # 각각 미분\n",
    "        W.assign_sub(learning_rate * W_grad) # A = A - B A -= B\n",
    "        b.assign_sub(learning_rate * b_grad) # learning_rate가 크다면 크게 반영될 것이고 작게 반영하면 작게 반영됨.\n",
    "        if i % 10 == 0:\n",
    "            print(\"{:5}|{:10.4f}{:10.4}|{:10.6f}\".format(i,W.numpy(),b.numpy(),cost))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
